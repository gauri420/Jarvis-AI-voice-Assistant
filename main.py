import sys
import speech_recognition as sr
from PyQt5.QtWidgets import QApplication, QMainWindow
from PyQt5.QtGui import QMovie
from jarvis_ui import Ui_MainWindow  # The UI file generated by Qt Designer
from jarvisclass import JarvisBackend    # Your backend class

class JarvisGUI(QMainWindow, Ui_MainWindow):
    def __init__(self,youtube_api_key,openai_api_key,news_api_key):
        super().__init__()
        self.setupUi(self)
        
        # Instantiate the backend
        self.backend = JarvisBackend(youtube_api_key, openai_api_key, news_api_key)
        
        # Connect the speak button to a function
        self.speakbutton.clicked.connect(self.on_speak_button_clicked)
        
        # Set up the waveform animation (ensure waveform.gif exists in your directory)
        # self.movie = QMovie("waveform.gif")  
        # Optionally, check if the movie is valid
        # if not self.movie.isValid():
            # print("Error: waveform.gif failed to load.")
        # else:
            # self.wavelabel.setMovie(self.movie)
            # self.wavelabel.hide()  # Initially hide the waveform display
        
    def on_speak_button_clicked(self):
        # Example usage: trigger the backend command and update the label
        
        # Start the waveform animation
        # self.wavelabel.show()
        # if self.movie.isValid():
            # self.movie.start()
        
        # Here you would normally capture audio; for testing, let's simulate a command:.
        # recognizer = sr.Recognizer()
        self.backend.speak("Initializing Jarvis....")
        while True:
            try:
                # self.backend.speak("Initializing Jarvis....")
                with sr.Microphone() as source:
                #  try:
                      self.label.setText("Listening...")
                      print("Listening.......")
                      self.backend.recognizer.adjust_for_ambient_noise(source)
                      audio = self.backend.recognizer.listen(source, timeout=5, phrase_time_limit=3)
                      self.label.setText("Recognizing...")
                      print("Recognizing...")
                      trigger = self.backend.recognizer.recognize_google(audio)

                if trigger.lower() == "jarvis":
                    self.backend.speak("Yes?")
                    while True:
                       with sr.Microphone() as source:
                          self.label.setText("Jarvis Active....")
                          print("Jarvis Active....")
                          self.backend.recognizer.adjust_for_ambient_noise(source)
                          audio = self.backend.recognizer.listen(source, timeout=5, phrase_time_limit=3)
                          command = self.backend.recognizer.recognize_google(audio)
                          self.label.setText(command)
                          # self.backend.process_command(command)

                          response = self.backend.process_command(command)
                          self.label.setText(response)
                #  except sr.UnknownValueError:
                #         self.label.setText("Sorry, I couldn't understand.")
                #  except sr.RequestError as e:
                #         self.label.setText("Sorry, there was an error.")
                
            
            except sr.UnknownValueError:
                self.label.setText("Sorry, I couldn't understand.")
                print("Sorry, I did not understand that.")
            except sr.RequestError:
                self.label.setText("Sorry, there was an error.")
                print("Sorry, the service is down.")

'''     recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            try:
                self.label.setText("Listening...")
                # print("Listening...")  # Debugging print

                # Capture the audio input
                audio = recognizer.listen(source)

                # Convert speech to text
                command = recognizer.recognize_google(audio)
                # print(f"Recognized command: {command}")  # Debugging print

                # Process the command using the backend
                response = self.backend.process_command(command)

                # Update the label with the response
                self.label.setText(response)

            except sr.UnknownValueError:
                self.label.setText("Sorry, I couldn't understand.")
            except sr.RequestError as e:
                self.label.setText("Sorry, there was an error.")
                
'''      
        
        # Stop the waveform animation
        # if self.movie.isValid():
            # self.movie.stop()
        # self.wavelabel.hide()


    
app = QApplication(sys.argv)
window = JarvisGUI(youtube_api_key="Your_youtube_api",
        openai_api_key="your_open_api",
        news_api_key="news_api")
window.show()
sys.exit(app.exec_())